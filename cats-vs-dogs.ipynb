{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8b9adcc5-3417-4888-9455-5aef75e5163a"
    }
   },
   "source": [
    "# Computer Vision Workshop\n",
    "\n",
    "Dieses Tutorial zeigt, wie man mittels eines Neuronalen Netzwerks / Deep Learning einen Bild-Klassifizierer baut, der Katzenbilder von Hundebildern unterscheidet.\n",
    "\n",
    "Diese Aufgabenstellung kommt aus dem [\"Cats vs. Dogs\"](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition) Wettbewerb der Website Kaggle.\n",
    "\n",
    "Basis bildet ein Convolutional Neuronal Network (CNN) namens \"VGG16\", welches auf Basis der Daten des [Imagenet Datasets](http://image-net.org/synset?wnid=n02084071) vortrainiert wurde. Das Modell wird durch Umkonfiguration und Re-Training so angepasst, dass es die gestellte Aufgabe lösen kann.\n",
    "\n",
    "Die Grundlagen zu diesem Workshop kommen aus dem Deep Learning MOOC [fast.ai](http://fast.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "40b6e98a-bc3c-4dd6-ac74-5d7571d7313a"
    }
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "74cb107e-1859-441c-a32b-b01cd059e998"
    }
   },
   "source": [
    "Die Daten des Kaggle Wettbewerbs wurden schon vorbereitet und in der \"richtigen\" Struktur abgelegt.\n",
    "Das Verzeichnis `data` enthält die Trainings- und Validierungsdaten aus dem Dataset. Dabei sind die Bilder zu jeder zu erkennenden \"Klasse\" (Cats & Dogs in unserem Fall) in einem eigenen Unterverzeichnis abgelegt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! führt einen Shell-Befehl aus...\n",
    "!tree -d data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mal schauen, wieviele Dateien in den Trainings- und Validerungsdaten drin sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "20bc8fad-7e51-4e62-b04d-60aa45ed40f4"
    }
   },
   "outputs": [],
   "source": [
    "!echo -n \"Training cats: \" && ls data/train/cats | wc -w\n",
    "!echo -n \"Training dogs: \" && ls data/train/dogs | wc -w\n",
    "!echo -n \"Validation cats: \" && ls data/valid/cats | wc -w\n",
    "!echo -n \"Validation dogs: \" && ls data/valid/dogs | wc -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Verzeichnis `test` enthält die Bilder, die nicht klassifizert sind (deshalb das Unterverzeichnis `unknown`). Diese wollen wir nach dem Training bestimmen. Mal sehen, wieviele das sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo -n \"Test: \" && ls data/test/unknown | wc -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit wir am Code herumprobieren können, ohne gleich lange Laufzeiten aufgrund der vielen Dateien zu erhalten, gibt es noch ein `sample` Dataset, welches gleich aufgebaut ist, aber nur nur einen kleinen Teil der Daten enthält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!tree -d sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!echo -n \"Training cats: \" && ls sample/train/cats | wc -w\n",
    "!echo -n \"Training dogs: \" && ls sample/train/dogs | wc -w\n",
    "!echo -n \"Validation cats: \" && ls sample/valid/cats | wc -w\n",
    "!echo -n \"Validation dogs: \" && ls sample/valid/dogs | wc -w\n",
    "!echo -n \"Test: \" && ls sample/test/unknown | wc -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier setzen wir den Pfad für die Daten, mit denen wir arbeiten wollen (also `data` oder `sample`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "# path = \"sample/\"\n",
    "path = os.path.join(os.path.curdir,path)\n",
    "print path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir laden die Python Klasse, welche das Modell (ein CNN) in ein nettes, mehr oder weniger objektorientiertes API verpackt. Der Sourcecode dazu steht in der Datei `vgg16.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As large as you can, but no larger than 64 is recommended. \n",
    "# If you have an older or cheaper GPU, you'll run out of memory, so will have to decrease this.\n",
    "batch_size=64\n",
    "\n",
    "# Wie viele Durchläufe durch die Trainingsdaten sollen gemacht werden:\n",
    "epochs = 1\n",
    "\n",
    "# Import VGG16 class, and instantiate\n",
    "import vgg16; reload(vgg16)\n",
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir laden die Trainings- und Validierungsdaten als \"Batches\". `vgg.get_batches()` setzt voraus, dass die Daten in Unterverzeichnissen je Kategorie abgelegt sind. Genau das ist bei uns der Fall, wie wir oben gesehen haben.\n",
    "\n",
    "Dann wird das VGG16 Modell an unsere Aufgabe (\"cat or dog\" Klassifizierung) angepasst: `vgg.finetune()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = vgg.get_batches(os.path.join(path,'train'), batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(os.path.join(path,'valid'), batch_size=batch_size*2)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??vgg.ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt trainieren wir das Modell mit den Daten über `vgg.fit()`. Dabei wird in Wahrheit nur noch der letze (modifizierte) Layer des angepassten VGG16 Modells trainiert.\n",
    "\n",
    "Die angepassten Gewichte des Modells schreiben wir in eine Datei, so dass wir sie später wieder laden können und so nicht jedesmal das Training wiederholen müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning rate:\n",
    "vgg.model.optimizer.lr = 0.01\n",
    "\n",
    "results_path = os.path.join(path,'results')\n",
    "\n",
    "for epoch in range(1,epochs+1):\n",
    "    print 'fit epoch {}'.format(epoch)\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    weights_filename = os.path.join(results_path,'vgg_weights-{}.h5'.format(epoch))\n",
    "    print 'saving weights to {}'.format(weights_filename)\n",
    "    vgg.model.save_weights(weights_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersage / Klassifizierung (Prediction)\n",
    "\n",
    "Jetzt klassifizieren wir die Bilder, die im Unterverzeichnis 'test' abgelegt sind.\n",
    "\n",
    "Prediction Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_path = os.path.join(path,'test')\n",
    "predictions_file = os.path.join(path,'results/predictions.dat')\n",
    "filenames_file = os.path.join(path,'results/filenames.dat')\n",
    "\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction durchführen und Ergebnisse speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('start predicting at {}'.format(time.asctime()))\n",
    "batches, predictions = vgg.test(test_path,batch_size=batch_size*2)\n",
    "print('stop predicting at {}'.format(time.asctime()))\n",
    "\n",
    "utils.save_array(predictions_file, predictions)\n",
    "utils.save_array(filenames_file, batches.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mal ein paar Ergebnisse anschauen....\n",
    "\n",
    "Wir wählen zufällig ein paar Bilder aus und zeigen sie mit der Vorhersage an (`[Wahrscheinlichkeit Katze, Wahrscheinlichkeit Hund]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = utils.load_array(predictions_file)\n",
    "filenames = utils.load_array(filenames_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def plots_idx(idx, path, filenames, titles=None):\n",
    "    utils.plots([image.load_img(os.path.join(path,filenames[i])) for i in idx], titles=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(batches.filenames),4)\n",
    "plots_idx(idx, path=path+'test/', filenames=batches.filenames, titles=predictions[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisieren\n",
    "\n",
    "Wir wollen uns anschauen, wie gut unser Modell eigentlich vorhersagt. Die Idee dazu ist, dass wir mit dem Modell eine Vorhersage über die bereits klassifizierten Trainingsdaten machen. So kennen wir die \"ground truth\" zu jedem Bild und können ermitteln, ob die Vorhersage korrekt war."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not 'path' in locals():\n",
    "    path = \"sample/\"\n",
    "    # path = \"data/\"\n",
    "\n",
    "#import numpy as np\n",
    "import utils; reload(utils)\n",
    "#import vgg16; reload(vgg16)\n",
    "#from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die trainierten Gewichte werden in das Modell geladen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "\n",
    "weights_filename = '{path}results/vgg_weights-{epoch}.h5'.format(path=path,epoch=1)\n",
    "vgg.model.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorhersage mit den Validierungsdaten. So kennnen wir die \"ground truth\" und können sie mit der Vorhersage des Modells vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_batches, predictions = vgg.test(path+'valid', batch_size=64)\n",
    "expected_labels = valid_batches.classes\n",
    "filenames = valid_batches.filenames\n",
    "\n",
    "print predictions[:8]\n",
    "\n",
    "our_predictions = predictions[:,0]\n",
    "our_labels = np.round(1-our_predictions)\n",
    "print our_labels[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeige einige korrekte Klassifizierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found {} correct labels\".format(len(correct))\n",
    "idx = np.random.permutation(correct)[:4]\n",
    "plots_idx(idx, path+'valid', filenames, our_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Zeige einige falsche Klassifizierungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found {} incorrect labels.\".format(len(incorrect))\n",
    "idx = np.random.permutation(incorrect)[:4]\n",
    "plots_idx(idx, path+'valid', filenames, our_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeige einige richtige Klassifizierungen mit der größten Wahrscheintlichkeit\n",
    "\n",
    "... also da, wo das Modell wirklich recht hatte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confident_cats = np.where((our_labels==expected_labels) & (our_labels==0))[0]\n",
    "print \"Found {} confident correct cats labels\".format(len(confident_cats))\n",
    "idx = np.random.permutation(confident_cats)[:4]\n",
    "plots_idx(idx,path+'valid', filenames, our_labels[idx])\n",
    "\n",
    "confident_dogs = np.where((our_labels==expected_labels) & (our_labels==1))[0]\n",
    "print \"Found {} confident correct dogs labels\".format(len(confident_dogs))\n",
    "idx = np.random.permutation(confident_dogs)[:4]\n",
    "plots_idx(idx,path+'valid', filenames, our_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ziege einige falsche Klassifizierungen mit der größten Wahrscheinlichkeit\n",
    "\n",
    "... also die, bei denen das Modell total daneben lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confident_cats = np.where((our_labels!=expected_labels) & (our_labels==0))[0]\n",
    "print \"Found {} confident incorrect cats labels\".format(len(confident_cats))\n",
    "if len(confident_cats)>0:\n",
    "    idx = np.random.permutation(confident_cats)[:4]\n",
    "    plots_idx(idx,path+'valid', filenames, our_labels[idx])\n",
    "\n",
    "confident_dogs = np.where((our_labels!=expected_labels) & (our_labels==1))[0]\n",
    "print \"Found {} confident incorrect dogs labels\".format(len(confident_dogs))\n",
    "if len(confident_dogs)>0:\n",
    "    idx = np.random.permutation(confident_dogs)[:4]\n",
    "    plots_idx(idx,path+'valid', filenames, our_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ziege die unsichersten Klassifizierungen\n",
    "\n",
    "... also die, bei denen sich das Modell nicht so sicher war."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(uncertain[:6],path+'valid', filenames, our_predictions[uncertain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels,our_labels)\n",
    "utils.plot_confusion_matrix(cm, valid_batches.class_indices)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8b9adcc5-3417-4888-9455-5aef75e5163a",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.11829268292682926,
        "y": 0.1021680216802168
       },
       "content": {
        "cell": "20bc8fad-7e51-4e62-b04d-60aa45ed40f4",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     },
     "theme": null
    }
   },
   "themes": {
    "default": "f6b1bd64-6a8a-49df-808e-fba1b5799bfb",
    "theme": {
     "f6b1bd64-6a8a-49df-808e-fba1b5799bfb": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "f6b1bd64-6a8a-49df-808e-fba1b5799bfb",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
