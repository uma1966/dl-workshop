{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook stammt ursprünglich von Microsoft und wurde über GitHub als Projekt [Coginitve-Vision-Python](https://github.com/Microsoft/Cognitive-Vision-Python) bereitgestellt. Hier wurden ein paar Anpassungen gemacht..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Oxford: Computer Vision API example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Jupyter notebook shows you how to get started with the Project Oxford <b>Computer Vision API</b> in Python, and how to visualize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this notebook, you will need to get keys to <b>Computer Vision API</b>. Visit <a href=\"https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision\">https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision</a>, and then the “Try Computer Vision API” button. On the “Sign in” page, use your Microsoft account to sign in and you will be able to subscribe to Computer Vision API and get free keys (Code of Conduct and TOS). After completing the sign-up process, paste your API key and API region into the variables section below. (Either the primary or the secondary key works.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "import requests\n",
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import library to display results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Display images within Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "_region = 'westeurope' #Here you enter the region of your subscription\n",
    "_url = 'https://{}.api.cognitive.microsoft.com/vision/v1.0/analyze'.format(_region)\n",
    "_key = 'ffea095cfb20426499353405b5f6d528' #Here you have to paste your primary key\n",
    "_maxNumRetries = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processRequest( json, data, headers, params ):\n",
    "\n",
    "    \"\"\"\n",
    "    Helper function to process the request to Project Oxford\n",
    "\n",
    "    Parameters:\n",
    "    json: Used when processing images from its URL. See API Documentation\n",
    "    data: Used when processing image read from disk. See API Documentation\n",
    "    headers: Used to pass the key information and the data type request\n",
    "    \"\"\"\n",
    "\n",
    "    retries = 0\n",
    "    result = None\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response = requests.request( 'post', _url, json = json, data = data, headers = headers, params = params )\n",
    "\n",
    "        if response.status_code == 429: \n",
    "\n",
    "            print( \"Message: %s\" % ( response.json() ) )\n",
    "\n",
    "            if retries <= _maxNumRetries: \n",
    "                time.sleep(1) \n",
    "                retries += 1\n",
    "                continue\n",
    "            else: \n",
    "                print( 'Error: failed after retrying!' )\n",
    "                break\n",
    "\n",
    "        elif response.status_code == 200 or response.status_code == 201:\n",
    "\n",
    "            if 'content-length' in response.headers and int(response.headers['content-length']) == 0: \n",
    "                result = None \n",
    "            elif 'content-type' in response.headers and isinstance(response.headers['content-type'], str): \n",
    "                if 'application/json' in response.headers['content-type'].lower(): \n",
    "                    result = response.json() if response.content else None \n",
    "                elif 'image' in response.headers['content-type'].lower(): \n",
    "                    result = response.content\n",
    "        else:\n",
    "            print( \"Error code: %d\" % ( response.status_code ) )\n",
    "            print( \"Message: %s\" % ( response.json() ) )\n",
    "\n",
    "        break\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_result(result):\n",
    "    if 'tags' in result:\n",
    "        print('Tags:')\n",
    "        for d in result['tags']:\n",
    "            print(d['name'] + ' (' + str(d['confidence']) + ') ')\n",
    "\n",
    "    if 'categories' in result:\n",
    "        print('\\nCategories:')\n",
    "        for d in result['categories']:\n",
    "            print(d['name'] + ' (' + str(d['score']) + ') ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of an image stored on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, os.path, random\n",
    "\n",
    "# Load raw image file into memory\n",
    "path = 'data/test/unknown'\n",
    "files = os.listdir(path)\n",
    "pathToFileInDisk = os.path.join(path,files[random.randrange(0, len(files))])\n",
    "print(pathToFileInDisk)\n",
    "with open( pathToFileInDisk, 'rb' ) as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# Computer Vision parameters\n",
    "params = { 'visualFeatures' : 'Color,Categories,Tags'} \n",
    "\n",
    "headers = dict()\n",
    "headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "headers['Content-Type'] = 'application/octet-stream'\n",
    "\n",
    "json = None\n",
    "\n",
    "result = processRequest( json, data, headers, params )\n",
    "\n",
    "if result is not None:\n",
    "    # Load the original image, fetched from the URL\n",
    "    data8uint = np.fromstring( data, np.uint8 ) # Convert string to an unsigned int array\n",
    "    img = cv2.cvtColor( cv2.imdecode( data8uint, cv2.IMREAD_COLOR ), cv2.COLOR_BGR2RGB )\n",
    "    ig, ax = plt.subplots()\n",
    "    ax.imshow( img )\n",
    "    print_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of an image retrieved via URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# URL direction to image\n",
    "urlImage = 'https://oxfordportal.blob.core.windows.net/vision/Analysis/1.jpg'\n",
    "\n",
    "# Computer Vision parameters\n",
    "params = { 'visualFeatures' : 'Color,Categories,Tags'} \n",
    "\n",
    "headers = dict()\n",
    "headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "headers['Content-Type'] = 'application/json' \n",
    "\n",
    "req_json = { 'url': urlImage } \n",
    "data = None\n",
    "\n",
    "result = processRequest( req_json, data, headers, params )\n",
    "\n",
    "if result is not None:\n",
    "    # Load the original image, fetched from the URL\n",
    "    arr = np.asarray( bytearray( requests.get( urlImage ).content ), dtype=np.uint8 )\n",
    "    img = cv2.cvtColor( cv2.imdecode( arr, -1 ), cv2.COLOR_BGR2RGB )\n",
    "    ig, ax = plt.subplots()\n",
    "    ax.imshow( img )\n",
    "    print_result(result)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
